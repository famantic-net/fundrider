"""
# Synopsis

`python3 interactive_fund_plot.py [--bar] [-t  <directory>]  -r <directory> | :internal:`

Generates interactive fund series charts from CSV files.
Supports:
- Directory mode: Reads all fund_tables_<n>.csv in a directory, outputs individual HTMLs and a master index.
- STDIN mode: Reads a single CSV from stdin if no -t provided, outputs one chart.
- `-r :internal:` mode: Stores HTML in-memory (internal_html) and prints the master HTML to STDOUT.
- `--bar`: Creates fund score performance chart

# Description

Creates interactive fund charts from csv tables generated by `slice_fund_files.pl`.

The charts all converge to value 0 (zero) at the end which is the latest date. The fund data has been normalized for all funds each with respect to the latest date so that it's either higher or lower than zero. This makes comparison between the existing funds very easy. The funds chart series that are placed lower on the chart have had a better increase with respect to the current fund value and oppositely if the fund chart series is graphed higher in the plot with respect to the latest value at the far right it shows the fund losing value.

# Options

- --bar
  Creates a fund performance bar graph displaying which funds that have the best performance depending on a weighted calculation of a number of time windows:

  - week
  - two weeks
  - month
  - quarter
  - half year
  - year
  - 1,5 years
  - two years

  The weights can be adjusted interactively.

- -r
  Specifies directory where to store the fund charts, unless the word '`:internal:`' is given. If `-r` is omitted the fund charts will be written to the current directory.
  If '`:internal:`' is given no individual fund charts will be written and the aggregated html containing all charts will be printed on STDOUT. See examples below.
- -t
  Specifies the directory where the csv fund tables that were generated by `slice_fond_files.pl` are located. The csv fund tables are expected to have names as '`fund_tables_<number>.csv'`. This is how the names will be created by the analysis part '`slice_fond_files.pl`'.
  If `-t` is omitted, input is expected on STDIN in the same format as the the csv fund tables. Only one csv table is expected when receiving from STDIN. If a directory is given with `-r` the result will be written to the file '`fund_series_chart.html`'. If `-r :internal:` is given the output will to STDOUT. See examples below.

- --trace
  Works in conjunction with the `--bar` switch. Prints on STDERR how many data points each ingested fund has.
  Important for the weight calculations as the weight window will be set to zero if there are not enough data points for the period, and all longer periods.
  Short data availability (e.g. for new funds) will heavily affect fund scoring since only the shorter periods will be included in the score.

# Examples

- Read all csv tables in directory '`../tables`' named ' `fund_tables_<number>.csv'` and create a fund chart for each table in directory '`../results`'. Charts will be named '`fund_series_chart_<number>.html`'.

  `python3 interactive_fund_plot.py -t ../tables -r ../results`

- Read all csv tables in directory '`../tables`' named ' `fund_tables_<number>.csv`' and print to STDOUT.

  `python3 interactive_fund_plot.py -t ../tables -r :internal:`

- Same as previous but rediect STDOUT to '`../results/fund_series_charts.stdout.html`'.

  `python3 interactive_fund_plot.py -t ../tables -r :internal: > ../results/fund_series_charts.stdout.html`

- Take input from STDIN and write from STDOUT to '`../results/fund_series_chart.stdout.html`'.

  `cat ../tables/fund_tables_5.csv | python3 interactive_fund_plot.py -r :internal: > ../results/fund_series_chart.stdout.html`

- Take input from STDIN and write from result chart to directory '`../results`' in file '`fund_series_chart.html`'.

  `cat ../tables/fund_tables_5.csv | python3 interactive_fund_plot.py -r ../results`

- Create fund performance chart and print on STDOUT

  `python3 bin/interactive_fund_plot.py --bar -t tables -r :internal: > results/fund_series_scores.stdout.html
"""

import os
import re
import sys
import argparse
import json
import numpy as np
import pandas as pd
import plotly.graph_objs as go

# Parse command-line arguments
parser = argparse.ArgumentParser(
    description='Generate fund series charts from CSVs; supports time-series, bar-score mode, and stdin.'
)
parser.add_argument(
    '-t', dest='input_dir', default='.',
    help='Directory containing fund_tables_<n>.csv'
)
parser.add_argument(
    '-r', dest='output_dir', default='.',
    help='Directory to save HTML or ":internal:" to output HTML to stdout'
)
parser.add_argument(
    '--bar', dest='bar_mode', action='store_true',
    help='Generate performance bar chart instead of time-series'
)
parser.add_argument(
    '--trace', dest='trace_mode', action='store_true',
    help='Enable diagnostic trace messages to STDERR for bar chart mode calculations.'
)
args = parser.parse_args()

# Determine modes
internal_only = (args.output_dir == ':internal:')
use_stdin = (args.input_dir == '.' and not sys.stdin.isatty())
if not internal_only and not use_stdin:
    os.makedirs(args.output_dir, exist_ok=True)

# Common pandas CSV options
df_kwargs = dict(
    sep=';', decimal=',', skiprows=2, header=0,
    parse_dates=[0], dayfirst=True, na_values=[''], encoding='latin1'
)

# JS snippet for hover interactions (for time-series charts)
hover_js = '''<script>
(function() {
  document.querySelectorAll('.plotly-graph-div').forEach(function(gd) {
    // Trace hover
    gd.on('plotly_hover', function(data) {
      var ci = data.points[0].curveNumber;
      // Bold legend entry by index
      var legendTexts = gd.querySelectorAll('.legendtext');
      if (gd.data[ci] && legendTexts.length > ci) {
        var traceName = gd.data[ci].name; // Get name from trace data
        // Attempt to bold by matching name, then fall back to index if needed
        var foundMatchByName = false;
        legendTexts.forEach(el => {
          if(el.textContent.startsWith(traceName.split('<br>')[0])) { // Match primary name part if <br> is used
            el.style.fontWeight='bold';
            foundMatchByName = true;
          }
        });
        if (!foundMatchByName && legendTexts[ci]) {
             legendTexts[ci].style.fontWeight = 'bold';
        }
      } else if (legendTexts.length > ci && legendTexts[ci]) {
         legendTexts[ci].style.fontWeight = 'bold'; // Fallback if gd.data[ci] is undefined
      }
      // Thicken hovered line
      Plotly.restyle(gd, {'line.width':3}, [ci]);
    });
    gd.on('plotly_unhover', function() {
      // Reset legend text
      var texts = gd.querySelectorAll('.legendtext');
      texts.forEach(el => el.style.fontWeight = 'normal');
      // Reset all lines
      Plotly.restyle(gd, {'line.width':2}, Array.from({length:gd.data.length}, (_,j) => j));
    });
    // Legend hover
    function bindLegendHover() {
      var texts = gd.querySelectorAll('.legendtext');
      texts.forEach(function(el, i) {
        el.onmouseenter = function() {
          el.style.fontWeight = 'bold';
          Plotly.restyle(gd, {'line.width':3}, [i]);
        };
        el.onmouseleave = function() {
          el.style.fontWeight = 'normal';
          Plotly.restyle(gd, {'line.width':2}, Array.from({length:gd.data.length}, (_,j) => j));
        };
      });
    }
    gd.on('plotly_afterplot', bindLegendHover);
    gd.on('plotly_legendclick', function() { setTimeout(bindLegendHover, 0); });
  });
})();
</script>'''

# Helper: build HTML for time-series chart
def df_to_html(df, title=None, last_dates=None):
    num_series = len(df.columns) - 1 if 'Date' in df.columns else len(df.columns)
    base_h = max(500, num_series*25 + 100)
    height_px = int(base_h * 1.5)
    fig = go.Figure()
    for col in df.columns:
        if col=='Date': continue
        name = col
        if last_dates and col in last_dates:
            name = f"{col}<br>{last_dates[col]}"
        # Ensure data is numeric before potential exponentiation
        series_data = pd.to_numeric(df[col], errors='coerce')
        # The user's description of CSVs: "relative values ... normalization at the latest date ... all funds are at a value of zero on the last date"
        # "If it is positive, the value was higher, if it was negative, the value was lower."
        # "The more they have increased, the lower the curve on the left."
        # This implies the values are already in a relative form, not log-transformed in the CSVs for the purpose of this specific normalization.
        # The transformation `(10 ** series_data)` seems specific to a different data interpretation or chart type.
        # For consistency with the bar chart mode and the user's description of input data,
        # we should probably plot the series_data as is, or if a percentage is needed for hover,
        # it should be derived differently if series_data is not log10(percentage/100).
        # For now, let's assume series_data is what needs to be plotted directly.
        # The customdata for hover might need adjustment based on actual data meaning.
        # If 'series_data' represents the direct normalized values (e.g., -0.05 for a 5% drop from the end point),
        # then `customdata = series_data * 100` would be the percentage difference.
        custom_hover_data = 10 ** series_data * 100 # Series_data is the log10 fractional relative change

        fig.add_trace(go.Scatter(
            x=df['Date'], y=series_data, mode='lines', name=name, customdata=custom_hover_data,
            line=dict(width=2), hovertemplate=(
                '<b>Series:</b> %{fullData.name}<br>'
                '<b>Date:</b> %{x|%Y-%m-%d}<br>'
                '<b>Value:</b> %{y:.3f}<br>' # Displaying the direct normalized value
                '<b>Relative Change:</b> %{customdata:.1f}%<extra></extra>' # Displaying it as percentage
            )
        ))
    layout = dict(hovermode='closest', template='plotly_white', height=height_px,
                  yaxis=dict(zeroline=True, zerolinewidth=3, title='Normalized Value (0 = Last Date)'), # Clarified Y-axis title
                  xaxis=dict(title='Date'),
                  legend=dict(traceorder='normal'))
    if title: layout['title'] = dict(text=title, x=0.5, xanchor='center')
    fig.update_layout(**layout)
    html = fig.to_html(include_plotlyjs='cdn', full_html=True)
    if '</body>' in html:
        html = html.replace('</body>', hover_js + '\n</body>')
    else:
        html += hover_js
    return html

# Bar-chart mode function
def bar_chart_mode(input_dir, output_dir, internal, trace_enabled): # Added trace_enabled parameter
    import os, re, json, numpy as np, pandas as pd, plotly.graph_objs as go
    # Adjusted window sizes to ~71.5% of original calendar days, rounded
    # New window for 1.5 years (390 days) added
    windows = [5, 10, 21, 64, 129, 261, 390, 522] # Original: [7,  14,  30,  90,  180,  365, 730]
                                                  # New:      [5,  10,  21,  64,  129, 261, 390, 522] (approx 5/7ths for trading days)
    # Default weights for each window's percentage change, new weight for 390d window added
    init_weights = [0.3, 1.5, 2.5, 4, 3, 2, 1.5, 1]
    # Mapping for slider period labels, new label for 390d window added
    period_label_map = {
        5: 'Week',
        10: 'Fortnight',
        21: 'Month',
        64: 'Quarter',
        129: 'Half year',
        261: 'Year',
        390: '1.5 years', # New label
        522: '2 years'
    }


    pat = re.compile(r'fund_tables_(\d+)\.csv$')
    funds, data = [], [] # funds stores fund names, data stores list of [pct_change_w1, pct_change_w2, ...] for each fund
    # Ensure input_dir exists before listing files
    if not os.path.isdir(input_dir):
        print(f"Error: Input directory '{input_dir}' not found.", file=sys.stderr)
        sys.exit(1) # Critical error, so exit

    for fname in sorted(f for f in os.listdir(input_dir) if pat.match(f)):
        try:
            # Read CSV using common options defined globally
            df_temp = pd.read_csv(os.path.join(input_dir, fname), **df_kwargs)
            if df_temp.empty:
                # Warning if CSV is empty or becomes empty after skipping initial rows
                if trace_enabled: print(f"TRACE: File: {fname} - CSV empty or no data after skiprows. Skipping.", file=sys.stderr)
                print(f"Warning: CSV file {fname} is empty or has no data after skiprows. Skipping.", file=sys.stderr)
                continue
            # Rename the first column (assumed to be date) to 'Date'
            df_temp.rename(columns={df_temp.columns[0]: 'Date'}, inplace=True)
            # Set 'Date' column as index for easier time-series operations
            df_temp.set_index('Date', inplace=True)

            # Iterate through each column (each fund series) in the CSV
            for col in df_temp.columns:
                if col.startswith('Unnamed:'): # Skip any unnamed columns that might exist
                    if trace_enabled: print(f"TRACE: File: {fname}, Column: {col} - Skipping unnamed column.", file=sys.stderr)
                    continue
                # Convert column data to numeric, coercing errors to NaN, then drop NaNs
                # These are the 'ys' values for regression
                ys = pd.to_numeric(df_temp[col], errors='coerce').dropna().values
                if len(ys) == 0: # Skip if column becomes empty after coerce/dropna (e.g., all non-numeric)
                    if trace_enabled: print(f"TRACE: File: {fname}, Fund: {col} - No numeric data after cleaning (ys length is 0). Skipping fund.", file=sys.stderr)
                    print(f"Warning: Column '{col}' in {fname} has no numeric data after cleaning. Skipping.", file=sys.stderr)
                    continue

                pct = [] # List to store percentage changes for the current fund across different windows
                for w_idx, w in enumerate(windows): # Iterate through each defined window size (e.g., 5 days, 10 days, ...)
                    if trace_enabled:
                        print(f"TRACE: File: {fname}, Fund: {col}, Window: {w}d - Checking data points. Available ys length: {len(ys)}", file=sys.stderr)

                    if len(ys) < w:
                        # If fund history is shorter than the window, append 0 change
                        pct.append(0)
                        if trace_enabled:
                            print(f"TRACE: File: {fname}, Fund: {col}, Window: {w}d - Insufficient data points ({len(ys)} < {w}). Contribution set to 0.", file=sys.stderr)
                    else:
                        # Perform linear regression on the last 'w' data points
                        # np.arange(w) creates [0, 1, ..., w-1] as the x-values (time steps)
                        # ys[-w:] gets the last 'w' values of the fund series
                        # m is the slope of the regression line
                        m, _ = np.polyfit(np.arange(w), ys[-w:], 1)
                        # Calculate total relative change over the window based on the slope
                        # (w-1) because 'w' points span 'w-1' intervals
                        # Multiply by 100 to express as a percentage
                        current_pct_contribution = m * (w - 1) * 100
                        pct.append(current_pct_contribution)
                        if trace_enabled:
                            print(f"TRACE: File: {fname}, Fund: {col}, Window: {w}d - Sufficient data points ({len(ys)} >= {w}). Calculated slope (m): {m:.6f}, Contribution: {current_pct_contribution:.2f}%", file=sys.stderr)
                funds.append(col) # Add fund name
                data.append(pct)  # Add list of percentage changes for this fund
        except Exception as e:
            # Catch any other errors during file processing
            if trace_enabled: print(f"TRACE: File: {fname} - Error during processing: {e}", file=sys.stderr)
            print(f"Error processing file {fname}: {e}", file=sys.stderr)
            continue # Skip to the next file

    if not funds: # Check if any fund data was successfully processed
        if trace_enabled: print(f"TRACE: No valid fund data collected from {input_dir}. Exiting bar chart mode.", file=sys.stderr)
        print(f"No valid fund data collected from {input_dir}. Exiting bar chart mode.", file=sys.stderr)
        return # Use return if called as a function, or sys.exit if standalone script section

    # Calculate initial scores for each fund based on default weights
    # Each 'row' in 'data' is a list of percentage changes for a fund (now 8 elements long)
    # Each 'p' is a percentage change, each 'w_val' is its corresponding weight
    scores = [sum(p * w_val for p,w_val in zip(row, init_weights)) for row in data]

    # Prepare list of funds for dropdown, excluding any "Unnamed" columns that might have slipped through (safety)
    dropdown_funds = sorted([f for f in funds if not f.startswith('Unnamed:')])

    # Create the initial bar chart figure
    fig = go.Figure(go.Bar(x=funds, y=scores, marker_color='steelblue', name='Fund Scores')) # x should be all original funds for initial plot
    fig.update_layout(
        title='Current fund performance', template='plotly_white', height=600,
        xaxis=dict(showticklabels=False, title='Funds (Scroll/Isolate to see names)'), # Hide individual fund names on x-axis initially for clarity
        yaxis=dict(title='Score'), barmode='group' # Group barmode (though only one trace here, good practice)
    )
    fig_dict = fig.to_dict() # Convert Plotly figure to dictionary for JSON serialization
    fig_json = json.dumps(fig_dict) # Serialize to JSON string to embed in HTML/JS

    # HTML for the bar chart div
    body = (
        '<div id="bar-chart" style="width:100%; height:600px; margin-bottom:30px;"></div>'
        '<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>' # Include Plotly.js CDN
        f'<script>var figDataInit={fig_json};Plotly.newPlot("bar-chart",figDataInit.data,figDataInit.layout);</script>' # Initialize chart
    )

    # HTML for weight adjustment sliders
    # The table width might need adjustment if it gets too crowded with 8 sliders.
    # Consider making it 100% width and letting items wrap or adjust cell padding/spacing.
    # For now, keeping 80% but it might be tight.
    slider_html = '<table style="margin:auto; width:90%; border-spacing: 5px;"><tr>' # Increased width, reduced spacing
    for i, w_days in enumerate(windows): # w_days is the window size in days
        period_name = period_label_map.get(w_days, f"{w_days}d") # Get descriptive name or default to days
        slider_html += (
            '<td style="text-align:center; padding:8px; vertical-align:top; border: 1px solid #ddd; border-radius: 5px;">' # Reduced padding
            # Label for slider using the actual day count from the 'windows' list
            f'<div>Window {w_days}d</div>'
            f'<div>{period_name}</div>' # New line for descriptive period name
            f'<div>Weight: <span id="v{i}" style="font-weight:bold;">{init_weights[i]:.1f}</span></div>' # Display current weight value
            # Input range slider
            f'<div><input id="w{i}" data-index="{i}" type="range" min="0" max="10" step="0.1" '
            f'value="{init_weights[i]:.1f}" style="width:100%;"></div></td>'
        )
    slider_html += '</tr></table>'

    # HTML for fund selection dropdown and isolate/reset buttons
    select_html = (
        '<div style="text-align:center; margin:20px 0;">'
        # Multiple select box for funds
        f'<select id="fund-select" multiple size="{min(len(dropdown_funds), 10)}" '
        'style="width:300px; height:200px; overflow-y:auto; border: 1px solid #ccc; border-radius: 5px; padding: 5px;"></select><br/>'
        # Buttons for isolating selected funds or resetting view
        '<button id="isolate" style="margin:10px 5px; padding: 8px 15px; border-radius:5px; background-color:#4CAF50; color:white; border:none; cursor:pointer;">Isolate</button>'
        '<button id="reset" style="margin:10px 5px; padding: 8px 15px; border-radius:5px; background-color:#f44336; color:white; border:none; cursor:pointer;">Reset</button>'
        '</div>'
    )

    # JavaScript for dynamic score updates based on slider changes (including scroll wheel)
    post_js = f"""
<script>
  // Pass Python 'data' (list of lists of percentage changes) to JavaScript
  const percDataForPostJs = {json.dumps(data)};
  // Get all weight input slider elements
  const weightInputsForPostJs = Array.from(document.querySelectorAll('input[id^="w"]'));

  function updateScoresOnWeightChange() {{
    // Get current values from all weight sliders
    const currentWeights = weightInputsForPostJs.map(el => parseFloat(el.value));
    // Update the displayed weight values next to sliders
    currentWeights.forEach((val,i) => {{
        const vElement = document.getElementById('v'+i); // Span element for weight value
        if (vElement) {{ // Check if element exists
            vElement.textContent = val.toFixed(1); // Display with one decimal place
        }}
    }});
    // Recalculate scores for all funds using new weights
    const newYScores = percDataForPostJs.map(fundPerformanceRow =>
      fundPerformanceRow.reduce((scoreSum, perfPoint, i) => scoreSum + perfPoint * currentWeights[i], 0)
    );
    // Update the 'y' values (scores) of the bar chart
    Plotly.restyle('bar-chart', 'y', [newYScores]);
  }}

  weightInputsForPostJs.forEach(slider => {{
    // Event listener for 'input' (when slider is dragged or value changed via code that triggers input)
    slider.addEventListener('input', updateScoresOnWeightChange);

    // Event listener for 'wheel' (mouse scroll over slider)
    slider.addEventListener('wheel', function(event) {{
      event.preventDefault(); // Prevent page from scrolling

      const step = parseFloat(slider.step) || 0.1; // Get step from slider attribute, default to 0.1
      let currentValue = parseFloat(slider.value);
      const minVal = parseFloat(slider.min) || 0;   // Get min from slider attribute, default to 0
      const maxVal = parseFloat(slider.max) || 10;  // Get max from slider attribute, default to 10

      if (event.deltaY < 0) {{ // Wheel up increases value
        currentValue += step;
      }} else {{ // Wheel down decreases value
        currentValue -= step;
      }}

      // Clamp value to be within min/max range of the slider
      currentValue = Math.max(minVal, Math.min(maxVal, currentValue));

      slider.value = currentValue.toFixed(1); // Update slider's actual value (toFixed for precision)

      // Manually trigger the update function because changing .value programmatically doesn't fire 'input' event
      updateScoresOnWeightChange();
    }});
  }});
  // Initial scores are set by Plotly.newPlot using figDataInit.
  // No explicit call to updateScoresOnWeightChange() is needed here at load time.
</script>
"""
    # JavaScript for fund isolation functionality
    isolate_js = f"""
<script>
  // Pass Python 'funds' (original list of all fund names) and 'data' to JavaScript
  const allOriginalFunds = {json.dumps(funds)};
  const fundsForDropdown = {json.dumps(dropdown_funds)}; // Sorted list for the select element
  const percDataForIsolate = {json.dumps(data)}; // Same as percDataForPostJs if in same scope

  const fundSelectElement = document.getElementById('fund-select');
  // weightInputsForPostJs is already defined if post_js is included before this.
  // If these scripts were separate, it would need to be re-selected.

  // Populate the dropdown select element with fund names
  fundsForDropdown.forEach(fundName => {{
    const optionElement = document.createElement('option');
    optionElement.value = fundName;
    optionElement.text = fundName;
    fundSelectElement.appendChild(optionElement);
  }});

  function calculateAllCurrentScores() {{
    // Use weightInputsForPostJs as it's the one tied to the event listeners for updates
    const currentWeights = weightInputsForPostJs.map(el => parseFloat(el.value));
    // Recalculate all scores based on current weights
    return percDataForIsolate.map(fundPerformanceRow =>
      fundPerformanceRow.reduce((scoreSum, perfPoint, i) => scoreSum + perfPoint * currentWeights[i], 0)
    );
  }}

  document.getElementById('isolate').addEventListener('click', function() {{
    // Get names of funds selected in the dropdown
    const selectedFundNames = Array.from(fundSelectElement.selectedOptions).map(opt => opt.value);
    if (selectedFundNames.length === 0) {{ return; }} // Do nothing if no funds selected

    const allCurrentScores = calculateAllCurrentScores(); // Get scores for ALL funds with current weights

    // Get the indices of the selected funds in the *original* 'allOriginalFunds' list
    const indicesInOriginalList = selectedFundNames.map(name => allOriginalFunds.indexOf(name)).filter(index => index !== -1);

    // Filter x-values (fund names) to only include valid, selected funds
    const isolatedXValues = selectedFundNames.filter(name => allOriginalFunds.includes(name));
    // Get the scores for these selected funds using their original indices
    const isolatedYValues = indicesInOriginalList.map(index => allCurrentScores[index]);

    // Update the bar chart to show only the isolated funds and their scores
    Plotly.restyle('bar-chart', {{ 'x': [isolatedXValues], 'y': [isolatedYValues] }});
  }});

  document.getElementById('reset').addEventListener('click', function() {{
    fundSelectElement.selectedIndex = -1; // Clear selection in dropdown
    const allCurrentScores = calculateAllCurrentScores(); // Recalculate all scores
    // Reset chart to show all original funds and their current scores
    Plotly.restyle('bar-chart', {{ 'x': [allOriginalFunds], 'y': [allCurrentScores] }});
  }});
</script>
"""
    # Combine all HTML parts into a full page
    full_html = (
        '<!DOCTYPE html><html><head><meta charset="utf-8"><title>Fund Scores</title>'
        '<style>body {{ font-family: Arial, sans-serif; }}</style></head><body>'
        '<h1 style="text-align:center; color:#333;">Fund Performance Dashboard</h1>'
        '<h3 style="text-align:center; color:#555;">Adjust Scoring Weights</h3>'
        + slider_html
        + '<h3 style="text-align:center; margin-top:30px; color:#555;">Fund Scores Bar Chart</h3>'
        + body
        + '<div style="clear:both; margin-top:20px;"></div>'
        + '<h3 style="text-align:center; color:#555;">Isolate Funds</h3>'
        + select_html
        + post_js  # JS for slider interactions
        + isolate_js # JS for fund isolation
        + '</body></html>'
    )
    if internal: # If internal mode, print HTML to stdout
        print(full_html)
    else: # Otherwise, save to file
        out = os.path.join(output_dir, 'fund_series_scores.html')
        with open(out, 'w', encoding='utf-8') as f:
            f.write(full_html)
        print(f"Saved score chart to {out}", file=sys.stderr)

# STDIN single time-series
if use_stdin and not args.bar_mode:
    try:
        df0 = pd.read_csv(sys.stdin, **df_kwargs)
    except Exception as e:
        print(f"Error reading from stdin: {e}", file=sys.stderr)
        sys.exit(1)

    if df0.empty:
        print("Received empty or all-NA data from stdin after skiprows.", file=sys.stderr)
        sys.exit(1)

    df0.rename(columns={df0.columns[0]:'Date'}, inplace=True)
    df0.dropna(axis=1, how='all', inplace=True) # Drop columns that are all NA
    df0.dropna(subset=['Date'], how='all', inplace=True) # Drop rows where 'Date' itself is NA
    if df0.empty:
        print("Data became empty after initial NA handling from stdin.", file=sys.stderr)
        sys.exit(1)
    df0.set_index('Date', inplace=True)

    df0 = df0.dropna(axis=1, how='all') # Drop series that are entirely NA after setting index
    if df0.empty:
        print("No valid data series found after initial processing from stdin.", file=sys.stderr)
        sys.exit(1)

    # Get last valid date for each series to display in legend
    last_dates={c:df0[c].last_valid_index().strftime('%Y-%m-%d') for c in df0.columns if pd.notna(df0[c].last_valid_index())}

    # Ensure data is sorted by date if not already
    if not df0.index.is_monotonic_increasing:
        df0 = df0.sort_index()

    # Convert index to datetime objects, coercing errors
    df0.index = pd.to_datetime(df0.index, errors='coerce')
    df0 = df0[pd.notna(df0.index)] # Remove rows where date conversion failed

    if df0.empty:
        print("No valid dates found in stdin data after conversion.", file=sys.stderr)
        sys.exit(1)

    min_date, max_date = df0.index.min(), df0.index.max()
    if pd.isna(min_date) or pd.isna(max_date): # Check if date range is valid
        print("Could not determine a valid date range from stdin data.", file=sys.stderr)
        sys.exit(1)

    # Create a full date range and reindex/interpolate
    idx=pd.date_range(min_date, max_date, freq='D') # Daily frequency
    df=df0.reindex(idx).interpolate(method='time').reset_index()
    # Rename 'index' column (from reset_index) to 'Date' if 'Date' isn't already a column name
    if 'index' in df.columns and 'Date' not in df.columns:
        df.rename(columns={'index':'Date'}, inplace=True)

    if 'Date' in df.columns:
        date_column_data = df['Date']
        other_columns_df = df.drop(columns=['Date'])
        # Drop columns that are still all NaN after interpolation
        cleaned_other_columns_df = other_columns_df.dropna(axis=1, how='all')
        df = pd.concat([date_column_data, cleaned_other_columns_df], axis=1)

        if len(df.columns) <= 1 : # Only 'Date' column left, or empty
            print("No valid data series to plot after interpolation and cleaning from stdin (only Date column).", file=sys.stderr)
            sys.exit(1)
    else:
        print("Critical: 'Date' column missing after processing stdin. Cannot proceed.", file=sys.stderr)
        sys.exit(1)

    html=df_to_html(df,title='Fund Series Chart (from stdin)',last_dates=last_dates)
    if internal_only:
        print(html)
    else:
        outf=os.path.join(args.output_dir,'fund_series_chart_stdin.html')
        with open(outf,'w',encoding='utf-8') as f: f.write(html)
        print(f"Saved {outf}",file=sys.stderr)
    sys.exit(0) # Successfully processed stdin

# Bar-mode (triggered by --bar argument)
if args.bar_mode:
    if use_stdin: # Bar mode cannot use stdin as it expects a directory of CSVs
        print("Bar mode cannot be used with stdin input. Please provide an input directory with -t.", file=sys.stderr)
        sys.exit(1)
    # Pass the trace_mode argument to the function
    bar_chart_mode(args.input_dir, args.output_dir, internal_only, args.trace_mode)
    sys.exit(0) # Successfully processed bar mode

# Directory time-series (default mode if not stdin or bar mode)
pat=re.compile(r'fund_tables_(\d+)\.csv$') # Regex to find and parse numbered CSV files
csv_files = []
if os.path.isdir(args.input_dir): # Check if input path is a directory
    csv_files = sorted(
        # Create list of (number, filepath) tuples, sorted by number
        (int(m.group(1)), os.path.join(args.input_dir, f))
        for f in os.listdir(args.input_dir) # Iterate over files in directory
        for m in [pat.match(f)] if m # Match regex and proceed if match found
    )
else: # Handle case where input_dir is not a directory
    if not (use_stdin or args.bar_mode): # If not other modes, then this is an error
        print(f"Error: Input directory '{args.input_dir}' not found or is not a directory.", file=sys.stderr)
        sys.exit(1)


if not csv_files and not (use_stdin or args.bar_mode): # Check only if this mode is active
    print(f"No CSVs matching 'fund_tables_<n>.csv' found in {args.input_dir}", file=sys.stderr)
    sys.exit(1) # Exit if no files found for this mode

htmls=[] # List to store names of generated HTML files (for index)
internal_html={} # Dictionary to store HTML content if internal_only
for idx_num, filepath in csv_files: # Iterate through sorted CSV files
    try:
        df0=pd.read_csv(filepath,**df_kwargs) # Read CSV
    except Exception as e:
        print(f"Error reading CSV file {filepath}: {e}", file=sys.stderr)
        continue # Skip to next file on error

    if df0.empty: # Check if DataFrame is empty after reading (e.g., due to skiprows)
        print(f"Warning: CSV file {filepath} is empty or has no data after skiprows. Skipping.", file=sys.stderr)
        continue

    df0.rename(columns={df0.columns[0]:'Date'},inplace=True) # Rename first column to 'Date'
    df0.dropna(axis=1,how='all',inplace=True) # Drop columns that are entirely NA
    df0.dropna(subset=['Date'], how='all', inplace=True) # Drop rows where 'Date' itself is NA
    if df0.empty:
        print(f"Data became empty for {filepath} after initial NA handling.", file=sys.stderr)
        continue
    df0.set_index('Date',inplace=True) # Set 'Date' as index

    df0 = df0.dropna(axis=1, how='all') # Drop series that are entirely NA after setting index
    if df0.empty:
        print(f"No valid data series in {filepath} after initial processing.", file=sys.stderr)
        continue

    # Get last valid date for each series
    last_dates={c:df0[c].last_valid_index().strftime('%Y-%m-%d') for c in df0.columns if pd.notna(df0[c].last_valid_index())}

    if not df0.index.is_monotonic_increasing: # Sort by date if not already
        df0 = df0.sort_index()

    df0.index = pd.to_datetime(df0.index, errors='coerce') # Convert index to datetime
    df0 = df0[pd.notna(df0.index)] # Remove rows with invalid dates

    if df0.empty:
        print(f"No valid dates in {filepath} after conversion. Skipping.", file=sys.stderr)
        continue

    min_date, max_date = df0.index.min(), df0.index.max() # Get date range
    if pd.isna(min_date) or pd.isna(max_date):
        print(f"Could not determine a valid date range from {filepath}. Skipping.", file=sys.stderr)
        continue

    idxr=pd.date_range(min_date,max_date,freq='D') # Create daily date range
    df=df0.reindex(idxr).interpolate(method='time').reset_index() # Reindex, interpolate, reset index
    if 'index' in df.columns and 'Date' not in df.columns: # Rename 'index' to 'Date' if needed
        df.rename(columns={'index':'Date'}, inplace=True)

    # Remove columns (except 'Date') that are still all NaN after interpolation
    if 'Date' in df.columns:
        date_column_data = df['Date']
        other_columns_df = df.drop(columns=['Date'])
        cleaned_other_columns_df = other_columns_df.dropna(axis=1, how='all')
        df = pd.concat([date_column_data, cleaned_other_columns_df], axis=1)

        if len(df.columns) <= 1: # Only 'Date' column (or fewer)
            print(f"No valid data series to plot in {filepath} after interpolation and cleaning (only Date column or empty).", file=sys.stderr)
            continue
    else: # Should not happen if logic is correct, but as a safeguard
        print(f"Warning: 'Date' column not found in DataFrame for {filepath} after reset_index. Skipping this file.", file=sys.stderr)
        continue

    # Generate HTML chart for the current file
    html=df_to_html(df,title=f'Fund Series Chart {idx_num}',last_dates=last_dates)
    if internal_only: # Store HTML internally if internal mode
        internal_html[idx_num]=html; print(f"Stored chart {idx_num} internally",file=sys.stderr)
    else: # Save HTML to file
        name=f'fund_series_chart_{idx_num}.html'
        p=os.path.join(args.output_dir,name)
        with open(p,'w',encoding='utf-8') as ff: ff.write(html)
        print(f"Saved {p}"); htmls.append(name) # Add filename to list for index

if not (use_stdin or args.bar_mode) and not htmls and not internal_html : # Check only if this mode was active
    print("No charts were generated from directory processing.", file=sys.stderr)
    # sys.exit(1) # Avoid exiting if other modes might have run or if this is not critical

# Master index (only if not in stdin mode or bar_mode, as they handle their own output/exit)
if not use_stdin and not args.bar_mode and (htmls or internal_html):
    base=['</body>','</html>'] # Base HTML tags
    lines=['<!DOCTYPE html>','<html lang="en">','<head>','  <meta charset="utf-8">',
           '  <meta name="viewport" content="width=device-width, initial-scale=1">',
           '  <title>Aggregated Fund Series Charts</title>',
           '  <style>body { font-family: Arial, sans-serif; margin: 0; padding: 0; background-color: #f4f4f4; } iframe { border: 1px solid #ccc; margin-bottom: 10px; } hr { display: none; }</style>',
           '</head>','<body>']
    lines.append('<h1 style="text-align:center; margin-top:20px; margin-bottom:20px;">Aggregated Fund Series Charts</h1>')

    if internal_only: # If internal mode, use srcdoc for iframes
        for idx_num in sorted(internal_html.keys()):
            c=internal_html[idx_num].replace('"','&quot;') # Escape quotes for srcdoc
            lines.append(f'<iframe title="Fund Series Chart {idx_num}" srcdoc="{c}" style="width:100%; height:850px; border:none;"></iframe>')
        print("\n".join(lines+base)) # Print combined HTML to stdout
    else: # If saving to files, link iframes by src
        for name in htmls: # Iterate through saved chart filenames
            lines.append(f'<iframe title="{name}" src="{name}" style="width:100%; height:850px; border:none;"></iframe>')
        lines+=base
        idxp=os.path.join(args.output_dir,'fund_series_charts_index.html') # Path for index file
        with open(idxp,'w',encoding='utf-8') as f:f.write("\n".join(lines)) # Write index file
        print(f"Generated index at {idxp}")
elif not use_stdin and not args.bar_mode: # If no charts generated in directory mode
    print("No charts to include in master index.", file=sys.stderr)
